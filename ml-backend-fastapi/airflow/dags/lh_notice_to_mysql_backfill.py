# -*- coding: utf-8 -*-

"""
LH ê³µê³ ë¬¸ ë°±í•„ DAG - ê°„ë‹¨ ë²„ì „

ê¸°ì¡´ í¬ë¡¤ë§ í•¨ìˆ˜ì˜ target_dateë§Œ ë°”ê¿”ê°€ë©° ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.providers.mysql.hooks.mysql import MySqlHook
import logging
import time
import json
from typing import List, Dict

# ì‹¤ì œ í¬ë¡¤ë§ í•¨ìˆ˜ ì„í¬íŠ¸
from plugins.crawlers.lh_crawler_for_mysql import (
    collect_lh_notices, 
    classify_notices_by_completeness
)

logger = logging.getLogger(__name__)

# ë°±í•„ ì„¤ì •
BACKFILL_CONFIG = {
    'start_date': datetime(2025, 1, 1).date(),      # ì‹œì‘ì¼
    'end_date': datetime(2025, 5, 26).date(),       # ì¢…ë£Œì¼ (ì–´ì œê¹Œì§€)
    'delay_between_dates': 3,                       # ë‚ ì§œ ê°„ 3ì´ˆ ëŒ€ê¸°
    'skip_weekends': True,                          # ì£¼ë§ ì œì™¸ ì—¬ë¶€
    'batch_size': 30,                               # 30ì¼ë§ˆë‹¤ ì¤‘ê°„ ë³´ê³ 
}

# LH í¬ë¡¤ë§ ì„¤ì •  
LH_CONFIG = {
    'list_url': 'https://apply.lh.or.kr/lhapply/apply/wt/wrtanc/selectWrtancList.do?viewType=srch',
    'headers': {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
}

# DAG ì •ì˜
backfill_dag = DAG(
    'LH_Notice_To_Mysql_Simple_Backfill',
    default_args={
        'owner': 'airflow',
        'depends_on_past': False,
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
        'execution_timeout': timedelta(hours=12),  # ìµœëŒ€ 12ì‹œê°„
    },
    description='LH ê³µê³ ë¬¸ ê°„ë‹¨ ë°±í•„ DAG',
    schedule=None,
    start_date=datetime(2025, 1, 1),
    catchup=False,
    max_active_runs=1,
    tags=['crawler', 'LH', 'backfill', 'simple']
)

def run_backfill_crawling(**context):
    """
    ë‚ ì§œë³„ë¡œ ìˆœì°¨ í¬ë¡¤ë§ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    """
    logger.info("ğŸš€ LH ë°±í•„ í¬ë¡¤ë§ ì‹œì‘")
    
    # ë‚ ì§œ ë²”ìœ„ ìƒì„±
    start_date = BACKFILL_CONFIG['start_date']
    end_date = BACKFILL_CONFIG['end_date']
    skip_weekends = BACKFILL_CONFIG['skip_weekends']
    
    # ì²˜ë¦¬í•  ë‚ ì§œ ëª©ë¡ ìƒì„±
    target_dates = []
    current_date = start_date
    
    while current_date <= end_date:
        # ì£¼ë§ ì œì™¸ ì˜µì…˜
        if skip_weekends and current_date.weekday() >= 5:
            current_date += timedelta(days=1)
            continue
        target_dates.append(current_date)
        current_date += timedelta(days=1)
    
    logger.info(f"ğŸ“… ì²˜ë¦¬ ëŒ€ìƒ: {start_date} ~ {end_date}")
    logger.info(f"ğŸ“Š ì´ {len(target_dates)}ì¼ ì²˜ë¦¬ ì˜ˆì •")
    if skip_weekends:
        logger.info("ğŸ“… ì£¼ë§ ì œì™¸ë¨")
    
    # MySQL ì—°ê²° í™•ì¸
    mysql_hook = MySqlHook(mysql_conn_id='notices_db')
    
    # í†µê³„ ë³€ìˆ˜
    total_processed = 0
    total_errors = 0
    daily_results = []
    
    # ë‚ ì§œë³„ í¬ë¡¤ë§ ì‹¤í–‰
    for idx, target_date in enumerate(target_dates):
        day_num = idx + 1
        logger.info(f"ğŸ“† [{day_num}/{len(target_dates)}] {target_date} í¬ë¡¤ë§ ì‹œì‘")
        
        try:
            # í•´ë‹¹ ë‚ ì§œ í¬ë¡¤ë§
            start_time = time.time()
            
            notices_data = collect_lh_notices(
                list_url=LH_CONFIG['list_url'],
                headers=LH_CONFIG['headers'],
                target_date=target_date
            )
            
            processing_time = time.time() - start_time
            
            if notices_data:
                logger.info(f"âœ… {target_date}: {len(notices_data)}ê°œ ê³µê³  ë°œê²¬ ({processing_time:.1f}ì´ˆ)")
                
                # ë°ì´í„° ë¶„ë¥˜
                csv_file_path = f"/opt/airflow/downloads/backfill_dag/mysql_failed_records/{target_date.strftime('%Y%m%d')}.csv"
                db_notices, csv_notices = classify_notices_by_completeness(notices_data, csv_file_path)
                
                # DB ì €ì¥
                saved_count = 0
                if db_notices:
                    saved_count = save_notices_to_db(db_notices, mysql_hook, target_date)
                    logger.info(f"ğŸ’¾ {target_date}: DBì— {saved_count}ê°œ ì €ì¥")
                
                if csv_notices:
                    logger.info(f"ğŸ“ {target_date}: CSVì— {len(csv_notices)}ê°œ ì €ì¥")
                
                total_processed += saved_count
                
                daily_results.append({
                    'date': target_date.strftime('%Y-%m-%d'),
                    'crawled': len(notices_data),
                    'db_saved': saved_count,
                    'csv_saved': len(csv_notices),
                    'processing_time': round(processing_time, 1),
                    'status': 'success'
                })
                
            else:
                logger.info(f"ğŸ“­ {target_date}: ê³µê³  ì—†ìŒ ({processing_time:.1f}ì´ˆ)")
                daily_results.append({
                    'date': target_date.strftime('%Y-%m-%d'),
                    'crawled': 0,
                    'db_saved': 0,
                    'csv_saved': 0,
                    'processing_time': round(processing_time, 1),
                    'status': 'no_data'
                })
            
            # ì¤‘ê°„ ë³´ê³  (30ì¼ë§ˆë‹¤)
            if day_num % BACKFILL_CONFIG['batch_size'] == 0:
                logger.info(f"ğŸ“Š ì¤‘ê°„ ë³´ê³  ({day_num}/{len(target_dates)}ì¼ ì™„ë£Œ)")
                logger.info(f"   - ëˆ„ì  DB ì €ì¥: {total_processed}ê±´")
                logger.info(f"   - ëˆ„ì  ì˜¤ë¥˜: {total_errors}ê±´")
                logger.info(f"   - ì§„í–‰ë¥ : {day_num/len(target_dates)*100:.1f}%")
            
            # ë‚ ì§œ ê°„ ëŒ€ê¸°
            if idx < len(target_dates) - 1:
                time.sleep(BACKFILL_CONFIG['delay_between_dates'])
                
        except Exception as e:
            logger.error(f"âŒ {target_date} í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
            total_errors += 1
            
            daily_results.append({
                'date': target_date.strftime('%Y-%m-%d'),
                'error': str(e),
                'status': 'error'
            })
            
            # ì—ëŸ¬ ì‹œ ë” ê¸´ ëŒ€ê¸°
            time.sleep(10)
    
    # ìµœì¢… ê²°ê³¼
    success_rate = (total_processed / (total_processed + total_errors) * 100) if (total_processed + total_errors) > 0 else 0
    
    result = {
        'total_dates': len(target_dates),
        'total_processed': total_processed,
        'total_errors': total_errors,
        'success_rate': success_rate,
        'start_date': start_date.strftime('%Y-%m-%d'),
        'end_date': end_date.strftime('%Y-%m-%d'),
        'daily_results': daily_results
    }
    
    logger.info(f"ğŸ‰ ë°±í•„ ì™„ë£Œ!")
    logger.info(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
    logger.info(f"   - ì²˜ë¦¬ ê¸°ê°„: {start_date} ~ {end_date}")
    logger.info(f"   - ì²˜ë¦¬ ë‚ ì§œ: {len(target_dates)}ì¼")
    logger.info(f"   - DB ì €ì¥: {total_processed}ê±´")
    logger.info(f"   - ì˜¤ë¥˜ ë°œìƒ: {total_errors}ê±´")
    logger.info(f"   - ì„±ê³µë¥ : {success_rate:.1f}%")
    
    return result

def save_notices_to_db(notices: List[Dict], mysql_hook: MySqlHook, target_date) -> int:
    """
    ê³µê³  ë°ì´í„°ë¥¼ MySQL DBì— ì €ì¥
    """
    if not notices:
        return 0
    
    saved_count = 0
    conn = None
    cursor = None
    
    try:
        conn = mysql_hook.get_conn()
        cursor = conn.cursor()
        conn.autocommit = False
        
        for notice in notices:
            try:
                # UpsertNotice í”„ë¡œì‹œì € ì‹¤í–‰
                params = (
                    notice['notice_number'],
                    notice['notice_title'],
                    notice['post_date'],
                    notice.get('application_end_date'),
                    notice.get('document_start_date'),
                    notice.get('document_end_date'),
                    notice.get('contract_start_date'),
                    notice.get('contract_end_date'),
                    notice.get('winning_date'),
                    notice.get('move_in_date'),
                    notice.get('location'),
                    notice.get('is_correction', False),
                    json.dumps(notice.get('supply_type', []), ensure_ascii=False),
                    json.dumps(notice.get('house_types', []), ensure_ascii=False)
                )
                
                cursor.callproc('UpsertNotice', params)
                conn.commit()
                
                # ì €ì¥ í™•ì¸
                verify_sql = "SELECT COUNT(*) FROM notices WHERE notice_number = %s"
                cursor.execute(verify_sql, (notice['notice_number'],))
                if cursor.fetchone()[0] > 0:
                    saved_count += 1
                
            except Exception as e:
                logger.error(f"âŒ ê³µê³  ì €ì¥ ì‹¤íŒ¨ {notice['notice_number']}: {str(e)}")
                conn.rollback()
                continue
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        try:
            cursor.callproc('UpdateAllNoticeStatuses')
            conn.commit()
        except Exception as e:
            logger.warning(f"âš ï¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        
    except Exception as e:
        logger.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        if conn:
            conn.rollback()
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()
    
    return saved_count

# Task ì •ì˜
start_task = EmptyOperator(
    task_id='start',
    dag=backfill_dag
)

crawl_task = PythonOperator(
    task_id='run_backfill',
    python_callable=run_backfill_crawling,
    dag=backfill_dag
)

end_task = EmptyOperator(
    task_id='end',
    dag=backfill_dag
)

# Task ì˜ì¡´ì„±
start_task >> crawl_task >> end_task

# DAG ë¬¸ì„œí™”
backfill_dag.doc_md = """
## LH ê³µê³ ë¬¸ ê°„ë‹¨ ë°±í•„ DAG

ê¸°ì¡´ í¬ë¡¤ë§ í•¨ìˆ˜ì˜ target_dateë§Œ ë°”ê¿”ê°€ë©° ê³¼ê±° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê°„ë‹¨í•œ ë°±í•„ DAG

### ğŸ¯ í•µì‹¬ ì•„ì´ë””ì–´:
- ë³µì¡í•œ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ì‹  **ë‚ ì§œë³„ ìˆœì°¨ í¬ë¡¤ë§**
- ê¸°ì¡´ `collect_lh_notices(target_date=ë‚ ì§œ)` í•¨ìˆ˜ ê·¸ëŒ€ë¡œ í™œìš©
- ì„¤ì •ë§Œ ë°”ê¾¸ë©´ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥

### âš™ï¸ ì„¤ì • ë³€ê²½:
```python
BACKFILL_CONFIG = {
    'start_date': datetime(2024, 6, 1).date(),    # ì‹œì‘ì¼
    'end_date': datetime(2024, 12, 31).date(),    # ì¢…ë£Œì¼
    'skip_weekends': True,                        # ì£¼ë§ ì œì™¸
    'delay_between_dates': 5,                     # ë‚ ì§œ ê°„ ëŒ€ê¸°(ì´ˆ)
}
```

### ğŸš€ ì‹¤í–‰:
```bash
airflow dags trigger LH_Notice_Simple_Backfill
```

### ğŸ“Š ì˜ˆìƒ ì‹œê°„:
- **1ë…„ (í‰ì¼ë§Œ)**: ì•½ 260ì¼ Ã— í‰ê·  30ì´ˆ = 2-3ì‹œê°„
- **6ê°œì›”**: ì•½ 130ì¼ Ã— í‰ê·  30ì´ˆ = 1-2ì‹œê°„
- **1ê°œì›”**: ì•½ 22ì¼ Ã— í‰ê·  30ì´ˆ = 10-15ë¶„

### ğŸ›¡ï¸ ì•ˆì „ì¥ì¹˜:
- ë‚ ì§œë³„ 3ì´ˆ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
- ì—ëŸ¬ ì‹œ ìë™ ìŠ¤í‚µ & 10ì´ˆ ëŒ€ê¸°
- 30ì¼ë§ˆë‹¤ ì¤‘ê°„ ì§„í–‰ë¥  ë³´ê³ 
- ì£¼ë§ ìë™ ì œì™¸ ì˜µì…˜

### ğŸ’¡ ì¥ì :
- **ë‹¨ìˆœí•¨**: ë³µì¡í•œ ë°°ì¹˜ ë¡œì§ ì—†ìŒ
- **ì•ˆì •ì„±**: ê¸°ì¡´ ê²€ì¦ëœ í¬ë¡¤ë§ í•¨ìˆ˜ ì‚¬ìš©  
- **ìœ ì—°ì„±**: ë‚ ì§œ ë²”ìœ„ ì‰½ê²Œ ì¡°ì •
- **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì§„í–‰ë¥  í™•ì¸
"""