# crawlers/lh_crawler.py - LH í¬ë¡¤ëŸ¬ ëª¨ë“ˆ
import time
import logging
from datetime import datetime
import requests
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException

import os
import csv
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional

from plugins.utils.web_helpers import init_driver

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ì„¤ì • í´ë˜ìŠ¤ ì¶”ê°€
@dataclass
class CrawlerConfig:
    """í¬ë¡¤ëŸ¬ ì„¤ì • í´ë˜ìŠ¤"""
    def __init__(self):
        self.navigation_wait_time = 2
        self.search_wait_time = 3
        self.detail_page_wait_time = 2

        # ì…€ë ‰í„° ì •ì˜
        self.search_button_id = "btnSah"
        self.notice_links_selector = "a.wrtancInfoBtn"

def collect_lh_notices(list_url, headers, target_date=None) -> List[Dict]:
    """
    LH ê³µê³ ë¬¸ í¬ë¡¤ë§ (ìˆœìˆ˜ í¬ë¡¤ë§ë§Œ, DB ì—°ê²° ì—†ìŒ)
    
    Args:
        list_url: ê³µê³  ëª©ë¡ URL
        headers: HTTP í—¤ë”
        target_date: ì¡°íšŒ ëŒ€ìƒ ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    
    Returns:
        List[Dict]: í¬ë¡¤ë§ëœ ê³µê³  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    logger.info("LH ê³µê³ ë¬¸ í¬ë¡¤ë§ ì‹œì‘")
    
    config = CrawlerConfig()
    
    notices_data = []
    
    driver = None
    session = None
    
    try:
        # ì„¸ì…˜ ì´ˆê¸°í™”
        session = requests.Session()
        session.headers.update(headers)
        logger.info("ğŸŒ HTTP ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì›¹ ë“œë¼ì´ë²„ ì´ˆê¸°í™”
        logger.info("ğŸš€ ì›¹ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...")
        driver, wait = init_driver(headers=headers)
        logger.info("âœ… ì›¹ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ")

        # ê³µê³  ëª©ë¡ í˜ì´ì§€ ì ‘ì†
        logger.info(f"ğŸ“„ ê³µê³  ëª©ë¡ í˜ì´ì§€ ì ‘ì†: {list_url}")
        start_time = time.time()
        driver.get(list_url)
        load_time = time.time() - start_time
        time.sleep(config.navigation_wait_time)
        logger.info(f"âœ… í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ({load_time:.2f}ì´ˆ)")

        # ë‚ ì§œ ì„¤ì •
        if target_date is None:
            target_date = datetime.today().date()
        logger.info(f"ğŸ“… ì¡°íšŒ ë‚ ì§œ ì„¤ì •: {target_date}")
        
        # ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •
        logger.info("ğŸ”§ ê²€ìƒ‰ ì¡°ê±´ ì„¤ì • ì¤‘...")
        select_elements = {
            "ìœ í˜•": (By.ID, "srchTypeAisTpCd", "05"),
            "ê³ ì‹œ ìœ í˜•": (By.ID, "aisTpCdData05", ""),
            "ê³µê¸‰ì£¼ì²´": (By.ID, "cnpCd", ""),
            "ê³µê¸‰ìƒíƒœ": (By.ID, "panSs", ""),
            "ê³µê³ ëª… ê²€ìƒ‰ì–´" : (By.ID, "searchValue", "ì…ì£¼ì")
        }
        
        for name, (by, selector, value) in select_elements.items():
            try:
                element = wait.until(EC.presence_of_element_located((by, selector)))
                tag_name = element.tag_name.lower()

                if tag_name == "select":
                    Select(element).select_by_value(value)
                elif tag_name == "input":
                    element.clear()
                    element.send_keys(value)
                else:
                    logger.warning(f"âš ï¸ {name}: ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì†Œ íƒ€ì…: {tag_name}")

                logger.info(f"âœ“ {name} ì„¤ì • ì™„ë£Œ: {value}")

            except Exception as e:
                logger.warning(f"âš ï¸ {name} ì„¤ì • ì‹¤íŒ¨: {e}")
        
        # ë‚ ì§œ í•„í„°ë§
        date_str = target_date.strftime("%Y-%m-%d")
        for date_field in ["startDt", "endDt"]:
            try:
                date_input = driver.find_element(By.ID, date_field)
                driver.execute_script(
                    "arguments[0].removeAttribute('readonly'); arguments[0].value = arguments[1];",
                    date_input, date_str
                )
                logger.info(f"ğŸ“… ê³µê³  ê²€ìƒ‰ ë‚ ì§œ ì„¤ì • ì™„ë£Œ: {date_field} = {date_str}")
            except Exception as e:
                logger.warning(f"ğŸ“… ê³µê³  ê²€ìƒ‰ ë‚ ì§œ ì„¤ì • ì‹¤íŒ¨: {date_field}, ì˜¤ë¥˜: {e}")
        
        # ê²€ìƒ‰ ì‹¤í–‰
        logger.info("ğŸ” ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
        try:
            # ê²€ìƒ‰ ë²„íŠ¼ ì°¾ê¸° - ì—¬ëŸ¬ ë°©ë²• ì‹œë„
            search_button = None
            search_selectors = [
                (By.ID, config.search_button_id),
                (By.CSS_SELECTOR, f"#{config.search_button_id}"),
                (By.XPATH, f"//button[@id='{config.search_button_id}']"),
                (By.XPATH, "//button[contains(@class, 'search') or contains(text(), 'ê²€ìƒ‰')]")
            ]
            for selector_type, selector in search_selectors:
                try:
                    search_button = wait.until(EC.element_to_be_clickable((selector_type, selector)))
                    logger.info(f"âœ“ ê²€ìƒ‰ ë²„íŠ¼ ë°œê²¬: {selector_type} - {selector}")
                    break
                except:
                    continue
            if not search_button:
                raise Exception("âš ï¸ ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì „ ìŠ¤í¬ë¡¤
            try:
                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", search_button)
                time.sleep(0.5)
            except:
                pass

            # ê²€ìƒ‰ ì‹¤í–‰
            logger.info("ğŸ”„ ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì¤‘...")
            search_button.click()

            # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            time.sleep(config.search_wait_time)
            
            # ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
            try:
                # ê²°ê³¼ í…Œì´ë¸”ì´ë‚˜ ì˜¤ë¥˜ ë©”ì‹œì§€ í™•ì¸
                wait.until(lambda driver: (
                    driver.find_elements(By.CSS_SELECTOR, config.notice_links_selector) or
                    driver.find_elements(By.CSS_SELECTOR, ".noData") or
                    "ê²€ìƒ‰ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤" in driver.page_source
                ))
                logger.info("âœ… ê²€ìƒ‰ ì‹¤í–‰ ì™„ë£Œ")    
            except:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            
            # ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘
            try:
                logger.info("ğŸ” ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
                logger.info(f"í˜„ì¬ URL: {driver.current_url}")
                logger.info(f"í˜ì´ì§€ ì œëª©: {driver.title}")
                
                # í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰ ë²„íŠ¼ ì°¾ê¸°
                if config.search_button_id in driver.page_source:
                    logger.info(f"âœ“ í˜ì´ì§€ ì†ŒìŠ¤ì— '{config.search_button_id}' ì¡´ì¬")
                else:
                    logger.info(f"âŒ í˜ì´ì§€ ì†ŒìŠ¤ì— '{config.search_button_id}' ì—†ìŒ")
                
                # ëª¨ë“  ë²„íŠ¼ ì°¾ê¸°
                buttons = driver.find_elements(By.TAG_NAME, "button")
                logger.info(f"í˜ì´ì§€ ë‚´ ë²„íŠ¼ ìˆ˜: {len(buttons)}ê°œ")
                for i, button in enumerate(buttons[:5]):  # ì²˜ìŒ 5ê°œë§Œ
                    try:
                        button_id = button.get_attribute('id')
                        button_text = button.text.strip()
                        button_class = button.get_attribute('class')
                        logger.info(f"ë²„íŠ¼[{i}]: id='{button_id}', text='{button_text}', class='{button_class}'")
                    except:
                        pass
                
            except Exception as debug_error:
                logger.info(f"ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {debug_error}")
            
            raise
        
        # === ê³µê³  ëª©ë¡ ì¶”ì¶œ ===
        logger.info("ğŸ“‹ ê³µê³  ëª©ë¡ ì¶”ì¶œ ì¤‘...")
        row_links = driver.find_elements(By.CSS_SELECTOR, config.notice_links_selector)
        if not row_links:
            logger.info("ğŸ“­ ì˜¤ëŠ˜ì˜ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return notices_data
        
        logger.info(f"ğŸ“Š ë°œê²¬ëœ ê³µê³  ìˆ˜: {len(row_links)}ê°œ")
        logger.info("-" * 50)
        
        # ê° ê³µê³  ìƒì„¸ ë‚´ìš© ê¸ì–´ì˜¤ê¸°
        for idx in range(len(row_links)):
            try:
                # ë§¤ë²ˆ ìƒˆë¡œ ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
                row_links = driver.find_elements(By.CSS_SELECTOR, config.notice_links_selector)
                if idx >= len(row_links):
                    logger.warning(f"âš ï¸ì¸ë±ìŠ¤ ì´ˆê³¼: {idx} >= {len(row_links)}")
                    break
                
                link = row_links[idx]

                # ê³µê³ ì½”ë“œ ì¶”ì¶œ
                wrtan_no = link.get_attribute("data-id1")
                logger.info(f"ğŸ“„ [{idx+1}/{len(row_links)}] ê³µê³  ì²˜ë¦¬ ì‹œì‘: ê³µê³ ë²ˆí˜¸ {wrtan_no}")
                
                # ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™
                logger.info(f"â†’ ìƒì„¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
                logger.info(f"URL: {link.get_attribute('href')}")
                link.click()
                time.sleep(config.detail_page_wait_time)
                
                # ê³µê³  ì •ë³´ ì¶”ì¶œ ì‹œì‘
                logger.info(f"â†’ ê³µê³  ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ ì¤‘...")
                notice_data = extract_notice_data(driver, wrtan_no, target_date)
                if notice_data:
                    notices_data.append(notice_data)
                    logger.info(f"âœ… ê³µê³  ì²˜ë¦¬ ì™„ë£Œ: {notice_data.get('notice_number')}, {notice_data.get('notice_title')}")
                else:
                    logger.warning(f"âš ï¸ ê³µê³  ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨")
                
                # ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°
                try:
                    logger.info(f"â† ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ì¤‘...")
                    
                    # ë’¤ë¡œê°€ê¸°
                    driver.back()
                    wait.until(EC.element_to_be_clickable((By.ID, config.search_button_id)))
                    time.sleep(config.navigation_wait_time)
                    logger.info("âœ… ë¸Œë¼ìš°ì € ë’¤ë¡œê°€ê¸° ì„±ê³µ")

                except Exception as e:
                    logger.warning(f"âš ï¸ ëª©ë¡ ë³µê·€ ì‹¤íŒ¨: {e}")
                    
            except Exception as e:
                logger.error(f"âŒ ê³µê³  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {idx}): {e}")
                try:
                    driver.back()
                    time.sleep(config.navigation_wait_time)
                except:
                    pass
        
        logger.info("-" * 50)
        logger.info(f"ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ: {len(notices_data)}ê°œ ê³µê³  ìˆ˜ì§‘")
        logger.info("=" * 60)
        return notices_data
    
    except Exception as e:
        logger.error(f"âŒ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise

    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        if session:
            session.close()
            logger.info("âœ“ HTTP ì„¸ì…˜ ì¢…ë£Œ")
        
        if driver:
            try:
                driver.quit()
                logger.info("âœ“ ì›¹ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ì›¹ë“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        logger.info("ğŸ í¬ë¡¤ë§ ì„¸ì…˜ ì™„ì „ ì¢…ë£Œ")

def extract_notice_data(driver, wrtan_no: str, target_date: datetime.date) -> Optional[Dict]:
    """ê°œë³„ ê³µê³ ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    logger.debug(f"ğŸ“„ ê³µê³ ë²ˆí˜¸ {wrtan_no} ìƒì„¸ë‚´ìš© ì¶”ì¶œ ì‹œì‘:")

    try:
        # === ê¸°ë³¸ í˜ì´ì§€ ìƒíƒœ í™•ì¸ ===
        try:
            current_url = driver.current_url
            logger.debug(f"í˜„ì¬ í˜ì´ì§€ URL: {current_url}")
            
            # í˜ì´ì§€ ë¡œë“œ í™•ì¸
            if "error" in current_url.lower() or "404" in current_url:
                logger.warning(f"âš ï¸ ì˜ëª»ëœ í˜ì´ì§€ ì ‘ê·¼: {current_url}")
                return None
                
        except Exception as e:
            logger.debug(f"í˜ì´ì§€ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")

        # === ê³µê³ ì¼ ì¶”ì¶œ ===
        logger.debug(f"ğŸ“… ê³µê³ ì¼ ì¶”ì¶œ ì¤‘...")
        try:
            pub_date_text = driver.find_element(By.XPATH, "//li[strong[text()='ê³µê³ ì¼']]").text
            pub_date = pub_date_text.replace("ê³µê³ ì¼", "").strip().replace(".", "")
            if len(pub_date) == 8:
                formatted_pub_date = f"{pub_date[:4]}-{pub_date[4:6]}-{pub_date[6:8]}"
            else:
                formatted_pub_date = target_date.strftime("%Y-%m-%d")
        except Exception as e:
            pub_date = target_date.strftime("%Y%m%d")
            formatted_pub_date = target_date.strftime("%Y-%m-%d")
            logger.warning(f"ê³µê³ ì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({wrtan_no}): {e}")
        
        # === ê³µê³ ëª… ì¶”ì¶œ ===
        try:
             # ê°€ëŠ¥í•œ ì…€ë ‰í„°ë“¤
            title_selectors = [
                "h1", "h2", "h3",                          # í—¤ë”© íƒœê·¸
                ".bbsV_subject", ".bbs_subject",           # ì œëª© í´ë˜ìŠ¤
                ".title", ".subject",                      # ì¼ë°˜ì ì¸ ì œëª© í´ë˜ìŠ¤
                "#title", "#subject"                       # ID ê¸°ë°˜
            ]

            title = None
            for selector in title_selectors:
                title_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for title_element in title_elements:
                    text = title_element.text.strip()
                    if text and len(text) > 10:
                        title = text
                        logger.info(f"âœ“ ê³µê³ ëª…: {title}")
                        break
                if title:
                    break
        except Exception as e:
            title = f"ê³µê³  {wrtan_no}"
            logger.warning(f"âŒ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨ ({wrtan_no}): {e}")

        # ê³µê³  ë§ˆê°ì¼ ì¶”ì¶œ
        application_end_date = extract_application_end_date(driver)
        
        # ì†Œì¬ì§€ ì¶”ì¶œ
        address = extract_address_from_content(driver)

        # ê³µê¸‰ìœ í˜• êµ¬ë¶„ ì¶”ì¶œ
        supply_type = extract_supply_type(driver)
        
        # ê³µê¸‰ì¼ì • ì¶”ì¶œ (ë‹¹ì²¨ìë°œí‘œì¼ì/ë‹¹ì²¨ìì„œë¥˜ì œì¶œê¸°ê°„/ê³„ì•½ì²´ê²°ê¸°ê°„)
        supply_schedule = extract_supply_schedule(driver)
        
        # ì…ì£¼ì˜ˆì •ì›” ì¶”ì¶œ
        move_in_schedule = extract_move_in_schedule(driver)

        # ì£¼íƒí˜• ì •ë³´ ì¶”ì¶œ
        house_types = extract_house_types(driver)
        
        # ê³µê³  ë°ì´í„° êµ¬ì„±
        notice_data = {
            'notice_number': wrtan_no,                                                      # ê³µê³ ì½”ë“œ
            'notice_title': title,                                                          # ê³µê³ ëª…
            'post_date': formatted_pub_date,                                                # ê³µê³ ì¼ì
            'application_end_date': application_end_date,                                   # ê³µê³  ë§ˆê°ì¼
            'document_start_date': supply_schedule.get('document_start_date'),              # ë‹¹ì²¨ì ì„œë¥˜ì œì¶œ(ì‹œì‘ì¼)
            'document_end_date': supply_schedule.get('document_end_date'),                  # ë‹¹ì²¨ì ì„œë¥˜ì œì¶œ(ì¢…ë£Œì¼)
            'contract_start_date' : supply_schedule.get('contract_start_date'),             # ê³„ì•½ì²´ê²°ê¸°ê°„(ì‹œì‘ì¼)
            'contract_end_date' : supply_schedule.get('contract_end_date'),                 # ê³„ì•½ì²´ê²°ê¸°ê°„(ì¢…ë£Œì¼)
            'winning_date' : supply_schedule.get('ë‹¹ì²¨ì ë°œí‘œì¼ì'),                          # ë‹¹ì²¨ì ë°œí‘œì¼ì
            'move_in_date' : move_in_schedule,                                              # ì…ì£¼ì˜ˆì •ì›”
            'location': address,                                                            # ì†Œì¬ì§€
            'is_correction': detect_correction_notice(title),                               # ê³µê³ ëª…ì—ì„œ ì •ì •ê³µê³  í‚¤ì›Œë“œ ì—¬ë¶€
            'supply_type': supply_type,                                                     # ê³µê¸‰ìœ í˜•
            'house_types': house_types                                                      # ì£¼íƒí˜• ì •ë³´
        }
        
        logger.info(f"âœ… ê³µê³ ë²ˆí˜¸ {wrtan_no} ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")
        return notice_data
        
    except Exception as e:
        error_msg = f"âŒ ê³µê³ ë²ˆí˜¸ {wrtan_no} ê³µê³  ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        
        # ì‹¤íŒ¨ ì •ë³´ë¥¼ CSV íŒŒì¼ì— ì €ì¥
        try:
            current_url = driver.current_url
        except:
            current_url = "URL ì¶”ì¶œ ì‹¤íŒ¨"
            
        save_failed_notice_to_csv(
            wrtan_no, 
            target_date, 
            error_msg, 
            url=current_url
        )
        
        return None

def extract_application_end_date(driver) -> Optional[str]:
    """
    ê³µê³  ë§ˆê°ì¼ ì •ë³´ ì¶”ì¶œ (bbsV_data í´ë˜ìŠ¤ì—ì„œ)
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        Optional[str]: ê³µê³  ë§ˆê°ì¼ ì •ë³´ (ì˜ˆ: "2024-03-15"). ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    """
    logger.info("ğŸ” ê³µê³  ë§ˆê°ì¼ ê²€ìƒ‰ ì¤‘...")
    
    try:
        # bbsV_data í´ë˜ìŠ¤ ë‚´ì—ì„œ ë§ˆê°ì¼ ì •ë³´ ì°¾ê¸°
        bbs_data = driver.find_elements(By.CSS_SELECTOR, ".bbsV_data li")
        
        for item in bbs_data:
            try:
                text = item.text.strip()
                # "ë§ˆê°ì¼2025.06.05" ë˜ëŠ” "ë§ˆê°ì¼ : 2025.06.04" í˜•ì‹ ëª¨ë‘ ì²˜ë¦¬
                if 'ë§ˆê°ì¼' in text:
                    import re
                    # ë‚ ì§œ ì¶”ì¶œì„ ìœ„í•œ ì •ê·œì‹ íŒ¨í„´
                    date_match = re.search(r'(\d{4})[.\-](\d{1,2})[.\-](\d{1,2})', text)
                    if date_match:
                        year, month, day = date_match.groups()
                        formatted_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                        if validate_date(formatted_date):
                            logger.info(f"âœ“ ë§ˆê°ì¼ ì¶”ì¶œ ì„±ê³µ: {formatted_date}")
                            return formatted_date
                        else:
                            logger.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ: {formatted_date}")
                    else:
                        logger.warning(f"âš ï¸ ë‚ ì§œ í˜•ì‹ ë§¤ì¹­ ì‹¤íŒ¨: {text}")
            except Exception as e:
                logger.debug(f"í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        logger.warning("âš ï¸ ê³µê³  ë§ˆê°ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None

    except Exception as e:
        logger.error(f"âŒ ë§ˆê°ì¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_move_in_schedule(driver) -> Optional[str]:
    """
    ì…ì£¼ì˜ˆì •ì›” ì •ë³´ ì¶”ì¶œ
    
    Args:
        driver: Selenium WebDriver ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        Optional[str]: ì…ì£¼ì˜ˆì •ì›” ì •ë³´ (ì˜ˆ: "2028ë…„ 01ì›”"). ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    """
    logger.info("ğŸ” ì…ì£¼ì˜ˆì •ì›” ê²€ìƒ‰ ì¤‘...")
    
    try:
        # ë°©ë²• 1: ë¦¬ìŠ¤íŠ¸ í•­ëª©ì—ì„œ ê²€ìƒ‰
        elements = driver.find_elements(By.CSS_SELECTOR, "ul.list_st1 li")
        for element in elements:
            text = element.text.strip()
            if 'ì…ì£¼ì˜ˆì •' in text:
                # ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                date_part = text.split(':')[-1].strip() if ':' in text else text
                logger.info(f"âœ… ë¦¬ìŠ¤íŠ¸ì—ì„œ ì…ì£¼ì˜ˆì •ì›” ì¶”ì¶œ ì„±ê³µ: {date_part}")
                return date_part

        # ë°©ë²• 2: ì§ì ‘ì ì¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰
        elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'ì…ì£¼ì˜ˆì •')]")
        for element in elements:
            text = element.text.strip()
            if 'ì…ì£¼ì˜ˆì •' in text:
                # ë¶€ëª¨ ìš”ì†Œì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                try:
                    full_text = element.find_element(By.XPATH, "..").text.strip()
                except:
                    full_text = text
                
                # "ì…ì£¼ì˜ˆì •ì›” : 2028ë…„ 01ì›”" í˜•ì‹ì—ì„œ ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                if ':' in full_text:
                    date_part = full_text.split(':')[-1].strip()
                    logger.info(f"âœ… í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì…ì£¼ì˜ˆì •ì›” ì¶”ì¶œ ì„±ê³µ: {date_part}")
                    return date_part
                elif 'ì…ì£¼ì˜ˆì •' in full_text:
                    # "ì…ì£¼ì˜ˆì • 2028ë…„ 01ì›”" í˜•ì‹ ì²˜ë¦¬
                    import re
                    date_match = re.search(r'(\d{4}ë…„\s*\d{1,2}ì›”)', full_text)
                    if date_match:
                        date_part = date_match.group(1)
                        logger.info(f"âœ… ì •ê·œì‹ìœ¼ë¡œ ì…ì£¼ì˜ˆì •ì›” ì¶”ì¶œ ì„±ê³µ: {date_part}")
                        return date_part

        # ë°©ë²• 3: classê°€ w100ì¸ ìš”ì†Œë“¤ ê²€ìƒ‰
        elements = driver.find_elements(By.CSS_SELECTOR, ".w100")
        for element in elements:
            text = element.text.strip()
            if 'ì…ì£¼ì˜ˆì •' in text:
                # ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                if ':' in text:
                    date_part = text.split(':')[-1].strip()
                    logger.info(f"âœ… w100 í´ë˜ìŠ¤ì—ì„œ ì…ì£¼ì˜ˆì •ì›” ì¶”ì¶œ ì„±ê³µ: {date_part}")
                    return date_part

        logger.warning("âš ï¸ ì…ì£¼ì˜ˆì •ì›” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None

    except Exception as e:
        logger.error(f"âŒ ì…ì£¼ì˜ˆì •ì›” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_address_from_content(driver) -> Optional[str]:
    """
    ê³µê³  ë‚´ìš©ì—ì„œ ì†Œì¬ì§€ ì •ë³´ ì¶”ì¶œ
    """
    try:
        logger.info("ğŸ” ì†Œì¬ì§€ ì •ë³´ ì¶”ì¶œ ì‹œì‘...")

        # .list_st1.li_w25 > li (li100 í´ë˜ìŠ¤ í¬í•¨ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ li ì „ì²´ íƒìƒ‰)
        location_elements = driver.find_elements(By.CSS_SELECTOR, ".list_st1.li_w25 > li")
        logger.info(f"âœ“ li ê°œìˆ˜: {len(location_elements)}")

        for idx, element in enumerate(location_elements):
            text = element.text.strip()
            logger.info(f"âœ“ [{idx}] li í…ìŠ¤íŠ¸: {text}")

            # "ì†Œì¬ì§€"ê°€ í¬í•¨ëœ ìš”ì†Œ íƒìƒ‰
            if "ì†Œì¬ì§€" in text:
                logger.info(f"âœ“ 'ì†Œì¬ì§€' í¬í•¨ li ë°œê²¬: {text}")

                # ì½œë¡ (:)ì´ ìˆìœ¼ë©´ ê·¸ ë’¤, ì—†ìœ¼ë©´ 'ì†Œì¬ì§€' ë’¤ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if ":" in text:
                    location = text.split(":", 1)[1].strip()
                else:
                    location = text.replace("ì†Œì¬ì§€", "").strip()

                logger.info(f"âœ“ ì†Œì¬ì§€ ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {location}")
                return location

        logger.warning("âš ï¸ ì†Œì¬ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None

    except Exception as e:
        logger.error(f"âŒ ì†Œì¬ì§€ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_supply_type(driver) -> Optional[str]:
    """ê³µê¸‰ì¼ì • í‘œì—ì„œ ê³µê¸‰ìœ í˜• êµ¬ë¶„ ì •ë³´ ì¶”ì¶œ"""
    logger.info("ğŸ” ê³µê¸‰ìœ í˜• êµ¬ë¶„ í…Œì´ë¸” ê²€ìƒ‰ ì‹œì‘...")
    
    try:
        # 1. ë¨¼ì € ê³µê¸‰ì¼ì • ì„¹ì…˜ì˜ í…Œì´ë¸” ì°¾ê¸°
        tables = driver.find_elements(By.CSS_SELECTOR, "div.tbl_st table")
        if not tables:
            # 2. ì‹¤íŒ¨ì‹œ ëª¨ë“  í…Œì´ë¸” ê²€ìƒ‰
            tables = driver.find_elements(By.CSS_SELECTOR, "table.tbl_st")
            logger.info("ì¼ë°˜ í…Œì´ë¸” ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        
        logger.info(f"âœ“ ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}ê°œ")
        
        for idx, table in enumerate(tables):
            try:
                # í…Œì´ë¸” í—¤ë” í™•ì¸
                headers = [th.text.strip() for th in table.find_elements(By.TAG_NAME, "th")]
                logger.info(f"í…Œì´ë¸” #{idx+1} í—¤ë”: {headers}")
                
                # ê³µê¸‰ì¼ì • í…Œì´ë¸”ì¸ì§€ í™•ì¸ (êµ¬ë¶„, ì‹ ì²­ì¼ì‹œ, ì‹ ì²­ë°©ë²• ì»¬ëŸ¼ì´ ìˆëŠ”ì§€)
                if any('êµ¬ë¶„' in h for h in headers) and any('ì‹ ì²­' in h for h in headers):
                    logger.info(f"âœ“ ê³µê¸‰ì¼ì • í…Œì´ë¸” ë°œê²¬! (í…Œì´ë¸” #{idx+1})")
                    
                    # ì²« ë²ˆì§¸ ì—´(êµ¬ë¶„) ë°ì´í„° ì¶”ì¶œ
                    rows = table.find_elements(By.TAG_NAME, "tr")[1:]  # í—¤ë” ì œì™¸
                    # ê° ê³µê¸‰ìœ í˜•ë³„ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ì–´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    types = []
                    
                    for row in rows:
                        try:
                            cells = row.find_elements(By.TAG_NAME, "td")
                            if cells:
                                type_text = cells[0].text.strip()  # ì²« ë²ˆì§¸ ì—´
                                if type_text and not any(skip in type_text.lower() for skip in ['í•©ê³„', 'ê³„']):
                                    types.append(type_text)
                                    logger.info(f" - ìœ í˜•: {type_text}")
                        except Exception as row_error:
                            logger.warning(f"âš ï¸ í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {row_error}")
                            continue
                    
                    if types:
                        logger.info(f"âœ… ê³µê¸‰ìœ í˜• ì¶”ì¶œ ì„±ê³µ! ì´ {len(types)}ê°œ ìœ í˜•")
                        return types
                    
            except Exception as table_error:
                logger.warning(f"âš ï¸ í…Œì´ë¸” #{idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {table_error}")
                continue
        
        logger.warning("âš ï¸ ê³µê¸‰ìœ í˜•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None

    except Exception as e:
        logger.error(f"âŒ ê³µê¸‰ìœ í˜• ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_supply_schedule(driver) -> Optional[dict]:
    """ê³µê¸‰ì¼ì • ì •ë³´ ì¶”ì¶œ"""
    logger.info(f"ğŸ” ê³µê¸‰ì¼ì • ê²€ìƒ‰ ì¤‘...")
    
    try:
        schedule_data = {}
        
        # === IDë¡œ ì§ì ‘ ì ‘ê·¼ (1ì°¨ ì‹œë„) ===
        logger.info(f"IDë¡œ ì§ì ‘ ì ‘ê·¼ ì‹œë„...")
        
        id_mappings = {
            'ë‹¹ì²¨ì ì„œë¥˜ì œì¶œê¸°ê°„': 'sta_PzwrPprSbmDt',
            'ë‹¹ì²¨ì ë°œí‘œì¼ì': 'sta_PzwrAncDt',
            'ê³„ì•½ì²´ê²°ê¸°ê°„': 'sta_ctrtStDt'  # ê³µë°± ì œê±°
        }
        
        for key, element_id in id_mappings.items():
            try:
                element = driver.find_element(By.ID, element_id)
                logger.info(f"âœ“ '{key}' - '{element_id}' ìš”ì†Œ ì°¾ìŒ")
                text = element.text.strip()
                
                if text and text.lower() != 'ì—†ìŒ':
                    if key in ['ë‹¹ì²¨ì ì„œë¥˜ì œì¶œê¸°ê°„', 'ê³„ì•½ì²´ê²°ê¸°ê°„']:
                        dates = parse_contract_period(text)
                        if dates:
                            if key == 'ë‹¹ì²¨ì ì„œë¥˜ì œì¶œê¸°ê°„':
                                schedule_data['document_start_date'] = dates['start_date']
                                schedule_data['document_end_date'] = dates['end_date']
                                logger.info(f"âœ“ '{key}' ê¸°ê°„ ë¶„ë¦¬: {dates['start_date']} ~ {dates['end_date']}")
                            else:  # ê³„ì•½ì²´ê²°ê¸°ê°„
                                schedule_data['contract_start_date'] = dates['start_date']
                                schedule_data['contract_end_date'] = dates['end_date']
                                logger.info(f"âœ“ '{key}' ê¸°ê°„ ë¶„ë¦¬: {dates['start_date']} ~ {dates['end_date']}")
                    else:  # ë‹¹ì²¨ì ë°œí‘œì¼ì
                        # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                        normalized_date = normalize_date(text)
                        if normalized_date:
                            schedule_data['ë‹¹ì²¨ì ë°œí‘œì¼ì'] = normalized_date
                            logger.info(f"âœ“ '{key}' ë‚ ì§œ ë³€í™˜: {normalized_date}")
                        else:
                            schedule_data[key] = text
                            logger.info(f"âš ï¸ '{key}' ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ ì €ì¥: {text}")
                else:
                    schedule_data[key] = "ì—†ìŒ"
                    logger.info(f"âš ï¸ '{key}' ê°’ì´ ë¹„ì–´ìˆê±°ë‚˜ 'ì—†ìŒ'")
                    
            except NoSuchElementException:
                logger.info(f"âŒ {key} ID '{element_id}' ìš”ì†Œ ì—†ìŒ")
            except Exception as e:
                logger.info(f"âš ï¸ {key} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # === í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ (2ì°¨ ì‹œë„) ===
        if not all(key in schedule_data for key in ['document_start_date', 'contract_start_date', 'ë‹¹ì²¨ì ë°œí‘œì¼ì']):
            logger.info("ğŸ“‹ í…Œì´ë¸”ì—ì„œ ê³µê¸‰ì¼ì • ê²€ìƒ‰ ì‹œë„...")
            
            tables = driver.find_elements(By.CSS_SELECTOR, "table.tbl_st")
            for table in tables:
                try:
                    headers = [th.text.strip() for th in table.find_elements(By.TAG_NAME, "th")]
                    if any('ì¼ì •' in h for h in headers):
                        rows = table.find_elements(By.TAG_NAME, "tr")
                        for row in rows:
                            cells = row.find_elements(By.TAG_NAME, "td")
                            if not cells:
                                continue
                                
                            row_text = row.text.strip()
                            
                            # ì„œë¥˜ì œì¶œê¸°ê°„ í™•ì¸
                            if 'ì„œë¥˜' in row_text and 'ì œì¶œ' in row_text and 'document_start_date' not in schedule_data:
                                dates = parse_contract_period(cells[-1].text.strip())
                                if dates:
                                    schedule_data['document_start_date'] = dates['start_date']
                                    schedule_data['document_end_date'] = dates['end_date']
                                    logger.info(f"âœ“ í…Œì´ë¸”ì—ì„œ ì„œë¥˜ì œì¶œê¸°ê°„ ë°œê²¬: {dates['start_date']} ~ {dates['end_date']}")
                            
                            # ê³„ì•½ì²´ê²°ê¸°ê°„ í™•ì¸
                            if 'ê³„ì•½' in row_text and 'contract_start_date' not in schedule_data:
                                dates = parse_contract_period(cells[-1].text.strip())
                                if dates:
                                    schedule_data['contract_start_date'] = dates['start_date']
                                    schedule_data['contract_end_date'] = dates['end_date']
                                    logger.info(f"âœ“ í…Œì´ë¸”ì—ì„œ ê³„ì•½ì²´ê²°ê¸°ê°„ ë°œê²¬: {dates['start_date']} ~ {dates['end_date']}")
                            
                            # ë‹¹ì²¨ì ë°œí‘œ í™•ì¸
                            if 'ë‹¹ì²¨' in row_text and 'ë°œí‘œ' in row_text and 'ë‹¹ì²¨ì ë°œí‘œì¼ì' not in schedule_data:
                                date_text = cells[-1].text.strip()
                                normalized_date = normalize_date(date_text)
                                if normalized_date:
                                    schedule_data['ë‹¹ì²¨ì ë°œí‘œì¼ì'] = normalized_date
                                    logger.info(f"âœ“ í…Œì´ë¸”ì—ì„œ ë‹¹ì²¨ì ë°œí‘œì¼ ë°œê²¬: {normalized_date}")
                
                except Exception as table_error:
                    logger.warning(f"âš ï¸ í…Œì´ë¸” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {table_error}")
                    continue
        
        # ê²°ê³¼ í™•ì¸ ë° ë°˜í™˜
        if schedule_data:
            logger.info(f"âœ… ê³µê¸‰ì¼ì • ì¶”ì¶œ ì™„ë£Œ ({len(schedule_data)}ê°œ í•­ëª©)")
            return schedule_data
        else:
            logger.warning("âš ï¸ ê³µê¸‰ì¼ì • ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
    except Exception as e:
        logger.error(f"âŒ ê³µê¸‰ì¼ì • ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_house_types(driver) -> List[Dict]:
    """ì£¼íƒí˜• ì •ë³´ ì¶”ì¶œ (ì£¼íƒí˜•, ì „ìš©ë©´ì , ì„¸ëŒ€ìˆ˜, í‰ê· ë¶„ì–‘ê°€)"""
    logger.info("ğŸ  ì£¼íƒí˜• ì •ë³´ ì¶”ì¶œ ì‹œì‘...")
    
    house_types = []
    
    try:
        # 1. ë¨¼ì € ì£¼íƒí˜• ì„¹ì…˜ì˜ í…Œì´ë¸” ì°¾ê¸°
        tables = driver.find_elements(By.CSS_SELECTOR, "div.tbl_st table")
        if not tables:
            # 2. ì‹¤íŒ¨ì‹œ ëª¨ë“  í…Œì´ë¸” ê²€ìƒ‰
            tables = driver.find_elements(By.CSS_SELECTOR, "table.tbl_st")
            logger.info("ì¼ë°˜ í…Œì´ë¸” ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        
        logger.info(f"âœ“ ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}ê°œ")
        
        for idx, table in enumerate(tables):
            try:
                # í…Œì´ë¸” í—¤ë” í™•ì¸
                headers = [th.text.strip() for th in table.find_elements(By.TAG_NAME, "th")]
                logger.info(f"í…Œì´ë¸” #{idx+1} í—¤ë”: {headers}")
                
                # ì£¼íƒí˜• í…Œì´ë¸”ì¸ì§€ í™•ì¸ (ì£¼íƒí˜•/íƒ€ì…, ì „ìš©ë©´ì , ì„¸ëŒ€ìˆ˜ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€)
                has_type = any(keyword in h for h in headers for keyword in ['ì£¼íƒí˜•', 'íƒ€ì…'])
                has_area = any(keyword in h for h in headers for keyword in ['ì „ìš©ë©´ì ', 'ì „ìš©'])
                has_count = any('ì„¸ëŒ€ìˆ˜' in h for h in headers)
                has_price = any('ë¶„ì–‘ê°€' in h for h in headers)
                
                if has_type and any([has_area, has_count, has_price]):
                    logger.info(f"âœ“ ì£¼íƒí˜• í…Œì´ë¸” ë°œê²¬! (í…Œì´ë¸” #{idx+1})")
                    
                    # ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
                    area_idx = next((i for i, h in enumerate(headers) if any(keyword in h for keyword in ['ì „ìš©ë©´ì ', 'ì „ìš©'])), None) - 1
                    count_idx = next((i for i, h in enumerate(headers) if 'ê¸ˆíšŒê³µê¸‰ ì„¸ëŒ€ìˆ˜' in h), None) - 1
                    price_idx = next((i for i, h in enumerate(headers) if 'í‰ê· ë¶„ì–‘' in h), None) - 1
                    
                    logger.info(f"ì»¬ëŸ¼ ì¸ë±ìŠ¤ - ì „ìš©ë©´ì : {area_idx}, ê¸ˆíšŒê³µê¸‰ ì„¸ëŒ€ìˆ˜: {count_idx}, í‰ê· ë¶„ì–‘ê°€ê²©(ì›): {price_idx}")
                    
                    # ë°ì´í„° í–‰ ì¶”ì¶œ
                    rows = table.find_elements(By.TAG_NAME, "tr")[1:]  # í—¤ë” ì œì™¸
                    logger.info(f"ë°œê²¬ëœ ë°ì´í„° í–‰ ìˆ˜: {len(rows)}ê°œ")
                    
                    for row_idx, row in enumerate(rows):
                        try:
                            # pc_red í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œì—ì„œ ì£¼íƒí˜• ì¶”ì¶œ
                            house_type_element = row.find_element(By.CSS_SELECTOR, "th.pc_red")
                            house_type = house_type_element.text.strip() if house_type_element else None
                            
                            cells = row.find_elements(By.TAG_NAME, "td")
                            
                            # ë°ì´í„° ì¶”ì¶œ
                            raw_data = {
                                'house_type': house_type,
                                'exclusive_area': cells[area_idx].text.strip() if area_idx is not None and area_idx < len(cells) else None,
                                'unit_count': cells[count_idx].text.strip() if count_idx is not None and count_idx < len(cells) else None,
                                'avg_price': cells[price_idx].text.strip() if price_idx is not None and price_idx < len(cells) else None
                            }
                            logger.info("=== ì¶”ì¶œëœ ì›ë³¸ ë°ì´í„° ===")
                            logger.info(raw_data)
                            cells = row.find_elements(By.TAG_NAME, "td")
                            # ê° ì…€ì˜ ì‹¤ì œ ê°’ì„ ëª¨ë‘ ë¡œê¹…
                            logger.info(f"=== í–‰ #{row_idx+1} ì „ì²´ ì…€ ë°ì´í„° ===")
                            for i, cell in enumerate(cells):
                                logger.info(f"ì…€[{i}]: '{cell.text.strip()}'")
                            
                            # pc_red í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œì—ì„œ ì£¼íƒí˜• ì¶”ì¶œ
                            house_type_element = row.find_element(By.CSS_SELECTOR, "th.pc_red")
                            house_type = house_type_element.text.strip() if house_type_element else None
                            logger.info(f"ì£¼íƒí˜•(pc_red): '{house_type}'")
                            
                            # ì¸ë±ìŠ¤ë³„ ì‹¤ì œ ë°ì´í„° ë¡œê¹…
                            logger.info("=== ì¸ë±ìŠ¤ë³„ ì¶”ì¶œ ë°ì´í„° ===")
                            logger.info(f"ì „ìš©ë©´ì ({area_idx}): '{cells[area_idx].text.strip() if area_idx is not None and area_idx < len(cells) else 'None'}'")
                            logger.info(f"ì„¸ëŒ€ìˆ˜({count_idx}): '{cells[count_idx].text.strip() if count_idx is not None and count_idx < len(cells) else 'None'}'")
                            logger.info(f"ë¶„ì–‘ê°€ê²©({price_idx}): '{cells[price_idx].text.strip() if price_idx is not None and price_idx < len(cells) else 'None'}'")
                            
                            # ì…€ ê°œìˆ˜ í™•ì¸
                            max_idx = max(filter(None, [area_idx, count_idx, price_idx]))
                            if len(cells) <= max_idx:
                                logger.warning(f"í–‰ #{row_idx+1}: ì…€ ê°œìˆ˜ ë¶€ì¡± (í•„ìš”: {max_idx+1}, ì‹¤ì œ: {len(cells)})")
                                continue
                            
                            logger.info("=== ì¶”ì¶œëœ ì›ë³¸ ë°ì´í„° ===")
                            logger.info(raw_data)
                            
                            # ë°ì´í„° ì •ì œ
                            house_info = {
                                'house_type': raw_data['house_type'],
                                'exclusive_area': clean_numeric_string(raw_data['exclusive_area']),
                                'unit_count': clean_numeric_string(raw_data['unit_count']),
                                'avg_price': clean_numeric_string(raw_data['avg_price'])
                            }
                            logger.info("=== ì •ì œëœ ë°ì´í„° ===")
                            logger.info(house_info)
                            
                            house_types.append(house_info)
                            logger.info(f"âœ“ í–‰ #{row_idx+1} ì£¼íƒí˜• ì •ë³´ ì¶”ì¶œ: {house_info} ì™„ë£Œ")
                            
                        except Exception as row_error:
                            logger.warning(f"âš ï¸ í–‰ #{row_idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {row_error}")
                            logger.exception(row_error)  # ìƒì„¸ ì—ëŸ¬ ë¡œê·¸ ì¶”ê°€
                            continue
                else:
                    logger.debug(f"í…Œì´ë¸” #{idx+1}ëŠ” ì£¼íƒí˜• í…Œì´ë¸”ì´ ì•„ë‹˜ (í—¤ë” ë¶ˆì¼ì¹˜)")
                    
            except Exception as table_error:
                logger.warning(f"âš ï¸ í…Œì´ë¸” #{idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {table_error}")
                continue
        
        if house_types:
            logger.info(f"âœ… ì´ {len(house_types)}ê°œ ì£¼íƒí˜• ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ ì£¼íƒí˜• ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return house_types
        
    except Exception as e:
        logger.error(f"âŒ ì£¼íƒí˜• ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def classify_notices_by_completeness(notices_data: List[Dict], csv_file_path: str) -> Tuple[List[Dict], List[Dict]]:
    """
    ë°ì´í„° ì™„ì„±ë„ì— ë”°ë¼ ê³µê³ ë¥¼ ë¶„ë¥˜
    - ëª¨ë“  í•„ë“œê°€ ìˆëŠ” ê³µê³ : DB ì €ì¥ìš©
    - í•˜ë‚˜ë¼ë„ í•„ë“œê°€ ì—†ëŠ” ê³µê³ : CSV ì €ì¥ìš©
    
    Args:
        notices_data: í¬ë¡¤ë§ëœ ê³µê³  ë°ì´í„°
        csv_file_path: CSV íŒŒì¼ ì €ì¥ ê²½ë¡œ
    
    Returns:
        Tuple[List[Dict], List[Dict]]: (DBìš© ê³µê³ , CSVìš© ê³µê³ )
    """
    db_notices = []
    csv_notices = []
    
    # í•„ìˆ˜ í•„ë“œ ì •ì˜ (DB í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê¸°ì¤€)
    required_fields = {
        'base': [  # notices í…Œì´ë¸” í•„ìˆ˜ í•„ë“œ
            'notice_number',          # ê³µê³ ë²ˆí˜¸
            'notice_title',           # ê³µê³ ëª…
            'post_date',             # ê³µê³ ì¼ì
            'application_end_date',   # ê³µê³  ë§ˆê°ì¼
            'document_start_date',    # ë‹¹ì²¨ì ì„œë¥˜ì œì¶œ(ì‹œì‘ì¼)
            'document_end_date',      # ë‹¹ì²¨ì ì„œë¥˜ì œì¶œ(ì¢…ë£Œì¼)
            'contract_start_date',    # ê³„ì•½ì²´ê²°ê¸°ê°„(ì‹œì‘ì¼)
            'contract_end_date',      # ê³„ì•½ì²´ê²°ê¸°ê°„(ì¢…ë£Œì¼)
            'winning_date',           # ë‹¹ì²¨ì ë°œí‘œì¼ì
            'move_in_date',          # ì…ì£¼ì˜ˆì •ì›”
            'location',              # ì†Œì¬ì§€
            'is_correction'          # ì •ì •ê³µê³  ì—¬ë¶€
        ],
        'supply_type': [  # supply_types í…Œì´ë¸” í•„ìˆ˜ í•„ë“œ
            'supply_type'            # ê³µê¸‰ìœ í˜•
        ],
        'house_type': [  # house_types í…Œì´ë¸” í•„ìˆ˜ í•„ë“œ
            'house_type',            # ì£¼íƒí˜•
            'exclusive_area',        # ì „ìš©ë©´ì 
            'unit_count',           # ì„¸ëŒ€ìˆ˜
            'avg_price'             # í‰ê· ë¶„ì–‘ê°€
        ]
    }
    
    # í•„ë“œ ê°’ ê²€ì¦ ë¡œì§ ê°•í™”
    def is_valid_field(value):
        if value is None:
            return False
        if isinstance(value, str) and (value.strip() == '' or value.lower() == 'ì—†ìŒ'):
            return False
        return True

    # ê° ê³µê³  ë°ì´í„° ê²€ì‚¬
    for notice in notices_data:
        is_complete = True
        missing_fields = []
        
        # 1. ê¸°ë³¸ í•„ë“œ ê²€ì‚¬
        for field in required_fields['base']:
            if not is_valid_field(notice.get(field)):
                is_complete = False
                missing_fields.append(field)
        
        # 2. ê³µê¸‰ìœ í˜• ê²€ì‚¬
        if not notice.get('supply_type') or not isinstance(notice['supply_type'], (list, tuple)):
            is_complete = False
            missing_fields.append('supply_type')
        
        # 3. ì£¼íƒí˜• ì •ë³´ ê²€ì‚¬
        if notice.get('house_types'):
            for house_type in notice['house_types']:
                for field in required_fields['house_type']:
                    if not house_type.get(field) or house_type.get(field) == 'ì—†ìŒ' or house_type.get(field) == '' or house_type.get(field) is None:
                        is_complete = False
                        missing_fields.append(f'house_type.{field}')
        else:
            is_complete = False
            missing_fields.append('house_types')
        
        # ë¶„ë¥˜ ë° ë¡œê¹…
        if is_complete:
            logger.info(f"âœ… DB ì €ì¥ ëŒ€ìƒ ê³µê³ : {notice.get('notice_number')} - ëª¨ë“  í•„ë“œ ì¡´ì¬")
            db_notices.append(notice)
        else:
            logger.info(f"ğŸ“ CSV ì €ì¥ ëŒ€ìƒ ê³µê³ : {notice.get('notice_number')} - ëˆ„ë½ í•„ë“œ: {', '.join(missing_fields)}")
            csv_notices.append(notice)
    
    # CSV ì €ì¥
    if csv_notices:
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)
        
        with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:
            # CSV í—¤ë” ì„¤ì • (DB í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê¸°ì¤€)
            fieldnames = [
                # notices í…Œì´ë¸” í•„ë“œ
                'notice_number', 'notice_title', 'post_date', 'application_end_date',
                'document_start_date', 'document_end_date',
                'contract_start_date', 'contract_end_date',
                'winning_date', 'move_in_date', 'location', 'is_correction',
                # house_types í…Œì´ë¸” í•„ë“œ
                'house_type', 'exclusive_area', 'unit_count', 'avg_price',
                # supply_types í…Œì´ë¸” í•„ë“œ
                'supply_type'
            ]
            
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            
            # ê° ê³µê³ ì™€ ì£¼íƒí˜• ì •ë³´ë¥¼ ê°œë³„ í–‰ìœ¼ë¡œ ì €ì¥
            for notice in csv_notices:
                # ê¸°ë³¸ ê³µê³  ì •ë³´
                base_data = {
                    'notice_number': notice.get('notice_number', ''),
                    'notice_title': notice.get('notice_title', ''),
                    'post_date': notice.get('post_date', ''),
                    'application_end_date': notice.get('application_end_date', ''),
                    'document_start_date': notice.get('document_start_date', ''),
                    'document_end_date': notice.get('document_end_date', ''),
                    'contract_start_date': notice.get('contract_start_date', ''),
                    'contract_end_date': notice.get('contract_end_date', ''),
                    'winning_date': notice.get('winning_date', ''),
                    'move_in_date': notice.get('move_in_date', ''),
                    'location': notice.get('location', ''),
                    'is_correction': notice.get('is_correction', False),
                    'supply_type': str(notice.get('supply_type', []))
                }
                
                # ì£¼íƒí˜• ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                if notice.get('house_types'):
                    for house_type in notice['house_types']:
                        row_data = base_data.copy()
                        row_data.update({
                            'house_type': house_type.get('house_type', ''),
                            'exclusive_area': house_type.get('exclusive_area', ''),
                            'unit_count': house_type.get('unit_count', ''),
                            'avg_price': house_type.get('avg_price', '')
                        })
                        writer.writerow(row_data)
                else:
                    # ì£¼íƒí˜• ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ë§Œ ì €ì¥
                    writer.writerow(base_data)
        
        logger.info(f"ğŸ“ CSV ì €ì¥ ì™„ë£Œ: {len(csv_notices)}ê°œ ê³µê³  -> {csv_file_path}")
        logger.info(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼ - DB ì €ì¥ ëŒ€ìƒ: {len(db_notices)}ê°œ ê³µê³ , CSV ì €ì¥ ëŒ€ìƒ: {len(csv_notices)}ê°œ ê³µê³ ")
    
    return db_notices, csv_notices

def save_failed_notice_to_csv(wrtan_no, target_date, error_msg, url=None):
    """ì‹¤íŒ¨í•œ ê³µê³  ì •ë³´ë¥¼ CSV íŒŒì¼ì— ì €ì¥"""
    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    log_dir = "/opt/airflow/downloads/failed_notices"
    os.makedirs(log_dir, exist_ok=True)
    
    # target_dateë¡œ íŒŒì¼ ì´ë¦„ ìƒì„±
    csv_file_path = f"{log_dir}/failed_notices_{target_date}.csv"
    
    # ì‹¤íŒ¨ ì •ë³´ ì¤€ë¹„
    failed_notice = {
        "notice_number": wrtan_no,
        "target_date": target_date.strftime("%Y-%m-%d") if hasattr(target_date, 'strftime') else str(target_date),
        "error_message": error_msg,
        "url": url or "URL ì—†ìŒ"
    }
    
    # CSV íŒŒì¼ì— ì¶”ê°€
    try:
        # í•„ë“œ ì´ë¦„ ì •ì˜
        fieldnames = ["notice_number", "target_date", "error_message", "url"]
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        file_exists = os.path.isfile(csv_file_path)
        
        # CSV íŒŒì¼ ì—´ê¸° (ì¶”ê°€ ëª¨ë“œ)
        with open(csv_file_path, 'a', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            # íŒŒì¼ì´ ìƒˆë¡œ ìƒì„±ëœ ê²½ìš° í—¤ë” ì‘ì„±
            if not file_exists:
                writer.writeheader()
            
            # ë°ì´í„° í–‰ ì¶”ê°€
            writer.writerow(failed_notice)
        
        logger.info(f"âœ… ì‹¤íŒ¨ ê³µê³  {wrtan_no} ì •ë³´ê°€ CSV íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_file_path}")
        return csv_file_path
    except Exception as e:
        logger.error(f"âš ï¸ ì‹¤íŒ¨ ê³µê³  ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    
def detect_correction_notice(title: str) -> bool:
    """ì œëª©ì—ì„œ ì •ì •ê³µê³  ì—¬ë¶€ íŒë³„"""
    if not title:
        logger.info("â“ ê³µê³ ëª… ì—†ìŒ")
        return False
    
    # ì •ì •ê³µê³  í‚¤ì›Œë“œ ëª©ë¡
    correction_keywords = ['ì •ì •', 'ë³€ê²½', 'ìˆ˜ì •', 'ì¬ê³µê³ ', 'ì·¨ì†Œ', 'ì—°ê¸°']
    
    logger.info(f"ğŸ” ê³µê³  ì œëª© ë¶„ì„: \"{title}\"")
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰ (ê° í‚¤ì›Œë“œë§ˆë‹¤ ê°œë³„ ë¡œê¹…)
    detected_keywords = []
    for keyword in correction_keywords:
        if keyword in title:
            detected_keywords.append(keyword)
            logger.info(f"- '{keyword}' í‚¤ì›Œë“œ ë°œê²¬")
    
    # ê²°ê³¼ ë¡œê¹…
    if detected_keywords:
        keywords_str = "', '".join(detected_keywords)
        logger.info(f"ğŸ”„ ì •ì •ê³µê³  ê°ì§€ë¨ - í‚¤ì›Œë“œ: '{keywords_str}'")
        return True
    else:
        logger.info(f"âœ… ì¼ë°˜ ê³µê³  (ì •ì •ê³µê³  ì•„ë‹˜)")
        return False

def parse_contract_period(text: str) -> Optional[dict]:
    """ê¸°ê°„ í…ìŠ¤íŠ¸ë¥¼ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ë¡œ ë¶„ë¦¬"""
    import re
    from datetime import datetime
    
    if not text:
        logger.warning("â“ ê¸°ê°„ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
        return None
    
    try:
        logger.info(f"ğŸ“… ê¸°ê°„ ë¶„ì„: \"{text}\"")
        
        # íŒ¨í„´ ì •ì˜ ë° ì„¤ëª…
        patterns = [
            (r'(\d{4}\.\d{2}\.\d{2})\s*~\s*(\d{4}\.\d{2}\.\d{2})', "ì—°.ì›”.ì¼ í˜•íƒœ"),
            (r'(\d{4}-\d{2}-\d{2})\s*~\s*(\d{4}-\d{2}-\d{2})', "ì—°-ì›”-ì¼ í˜•íƒœ"),
            (r'(\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼)\s*~\s*(\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼)', "í•œê¸€ í˜•íƒœ"),
            (r'(\d{1,2}\.\d{1,2})\s*~\s*(\d{1,2}\.\d{1,2})', "ì›”.ì¼ í˜•íƒœ")
        ]
        
        for i, (pattern, desc) in enumerate(patterns):
            match = re.search(pattern, text)
            if match:
                start_str = match.group(1).strip()
                end_str = match.group(2).strip()
                
                logger.debug(f"íŒ¨í„´ #{i+1} ({desc}) ë§¤ì¹­: '{start_str}' ~ '{end_str}'")
                
                # ë‚ ì§œ í‘œì¤€í™” (YYYY-MM-DD í˜•íƒœë¡œ)
                start_date = normalize_date(start_str)
                end_date = normalize_date(end_str)
                
                if start_date and end_date:
                    result = {
                        'start_date': start_date,
                        'end_date': end_date,
                        'original_text': text,
                        'pattern_matched': desc
                    }
                    logger.info(f"âœ… ê¸°ê°„ íŒŒì‹± ì„±ê³µ: {start_date} ~ {end_date}")
                    return result
                else:
                    logger.warning(f"âš ï¸ ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: '{start_str}' ~ '{end_str}'")
        
        # í…ìŠ¤íŠ¸ê°€ ìˆ«ìë‚˜ ë‚ ì§œ í˜•ì‹ì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸ (ë””ë²„ê¹…ìš©)
        has_numbers = bool(re.search(r'\d', text))
        has_tilde = '~' in text
        
        if has_numbers and has_tilde:
            logger.warning(f"â— ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: \"{text}\" - ìˆ«ìì™€ ë¬¼ê²°í‘œëŠ” ìˆìœ¼ë‚˜ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨")
        elif has_numbers:
            logger.warning(f"â— ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: \"{text}\" - ìˆ«ìëŠ” ìˆìœ¼ë‚˜ ë¬¼ê²°í‘œ(~) ì—†ìŒ")
        else:
            logger.warning(f"âŒ ê¸°ê°„ í˜•ì‹ ì•„ë‹˜: \"{text}\"")
        
        return None
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ê¸°ê°„ íŒŒì‹± ì˜¤ë¥˜: {str(e)}, ì…ë ¥: \"{text}\"")
        import traceback
        logger.debug(f"ğŸ”¬ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

def normalize_date(date_str: str) -> Optional[str]:
    """ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ì„ YYYY-MM-DDë¡œ í‘œì¤€í™”"""
    if not date_str or not isinstance(date_str, str):
        logger.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ ì…ë ¥: {date_str}")
        return None
    
    try:
        logger.debug(f"ğŸ—“ï¸ ë‚ ì§œ í‘œì¤€í™”: \"{date_str}\"")
        
        # ìˆ«ìë§Œ ì¶”ì¶œ
        import re
        numbers = re.findall(r'\d+', date_str)
        
        if len(numbers) >= 3:
            year = numbers[0] if len(numbers[0]) == 4 else None
            if year:
                month = numbers[1].zfill(2)
                day = numbers[2].zfill(2)
                
                result = f"{year}-{month}-{day}"
                if validate_date(result):
                    logger.debug(f"âœ… ë‚ ì§œ ë³€í™˜ ì„±ê³µ: \"{result}\"")
                    return result
                else:
                    logger.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ: {result}")
            else:
                logger.warning(f"âš ï¸ ì˜¬ë°”ë¥¸ ì—°ë„ í˜•ì‹ì´ ì•„ë‹˜: {numbers[0]}")
        else:
            logger.warning(f"âš ï¸ ì¶©ë¶„í•œ ë‚ ì§œ êµ¬ì„±ìš”ì†Œê°€ ì—†ìŒ: {date_str}")
        
        return None
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ë‚ ì§œ í‘œì¤€í™” ì˜¤ë¥˜: {e}, ì…ë ¥: \"{date_str}\"")
        return None

def validate_date(date_str: str) -> bool:
    """ë‚ ì§œ ë¬¸ìì—´ì˜ ìœ íš¨ì„± ê²€ì‚¬ (YYYY-MM-DD í˜•ì‹)"""
    from datetime import datetime
    try:
        if not date_str:
            return False
        
        # YYYY-MM-DD í˜•ì‹ì¸ì§€ í™•ì¸
        if not isinstance(date_str, str) or len(date_str.split('-')) != 3:
            return False
        
        # ì‹¤ì œ ë‚ ì§œë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
        year, month, day = map(int, date_str.split('-'))
        datetime(year, month, day)
        
        return True
    except ValueError:
        return False
    except Exception:
        return False

def clean_numeric_string(value: str) -> Optional[str]:
    """
    ìˆ«ì ë¬¸ìì—´ ì •ì œ (ì½¤ë§ˆ ì œê±°, ë‹¨ìœ„ ì œê±° ë“±)
    
    Args:
        value: ì •ì œí•  ë¬¸ìì—´
        
    Returns:
        Optional[str]: ì •ì œëœ ìˆ«ì ë¬¸ìì—´
    """
    if not value:
        return None
        
    try:
        # ì½¤ë§ˆ ì œê±°
        value = value.replace(',', '')
        
        # ìˆ«ìë§Œ ì¶”ì¶œ
        import re
        numbers = re.findall(r'\d+\.?\d*', value)
        if numbers:
            return numbers[0]
            
        return None
        
    except Exception:
        return None