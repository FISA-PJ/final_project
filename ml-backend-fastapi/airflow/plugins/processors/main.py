import os
from dotenv import load_dotenv
from langchain.schema import Document
from elasticsearch import Elasticsearch
from langchain_elasticsearch import ElasticsearchStore
import logging
from elasticsearch.exceptions import NotFoundError, TransportError
# from airflow.providers.elasticsearch.hooks.elasticsearch import ElasticsearchPythonHook


from plugins.processors.processor1_pdf2md import Parser2Markdown
from plugins.processors.processor2_chunking import HeaderSplitter, SemanticSplitter
from plugins.processors.processor3_embedding import BgeM3Embedding

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# í™˜ê²½ ì„¤ì •
load_dotenv()
os.chdir('/opt/airflow/downloads')

# Elasticsearch ì—°ê²°
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
preprocessor = Parser2Markdown(UPSTAGE_API_KEY)

embeddings = BgeM3Embedding()
header_splitter = HeaderSplitter()
second_splitter = SemanticSplitter(embeddings)
es =  Elasticsearch('http://airflow-elasticsearch:9200')
index_name = "test-0524-tmp"

vectorstore = ElasticsearchStore(
    index_name=index_name,
    embedding=embeddings,
    es_connection=es,
)

# # ì´ë¯¸ íŒŒì‹±ëœ íŒŒì¼ ì½ì–´ì˜¤ëŠ” ê²½ìš°
# def read_md_file(file_path):
#     with open(file_path, 'r', encoding='utf-8') as f:
#         return f.read()

def process_pdfs():
    # ì²˜ë¦¬í•  PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    process_files = os.getenv('PROCESS_PDF_FILES', '').split(',')
    if not process_files or process_files[0] == '':
        logger.warning("ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    #preprocessor = Parser2Markdown(UPSTAGE_API_KEY)
    #parent_splitter = HeaderSplitter()
    # docstore = ElasticsearchDocstore(
    #     index_name="parent-chunks-00",
    #     es=es,
    # )

    for file_name in process_files:
        file_path = os.path.join('.', file_name)
        if not os.path.exists(file_path):
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            continue
        
        logger.info(f"======== ğŸš©{file_name} íŒŒì¼ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ========")

        ## 1. ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ (Elasticsearch ì¿¼ë¦¬)
        apt_code = file_name.split('_')[0] # file_name
        try:
            if es.indices.exists(index=index_name):
                delete_query = {
                    "query": {
                        "term": {
                            "metadata.apt_code": apt_code
                        }
                    }
                }
                response = es.delete_by_query(index=index_name, body=delete_query)
                deleted_count = response.get("deleted", 0)
                logger.info(f"ğŸ—‘ï¸ apt_code={apt_code} ê´€ë ¨ ë¬¸ì„œ {deleted_count}ê°œ ì‚­ì œ ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ ì¸ë±ìŠ¤ {index_name}ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        except NotFoundError as e:
            logger.warning(f"ğŸš« ì‚­ì œ ì‹¤íŒ¨: (ë¬¸ì„œ ì—†ìŒ) {e}")

        except TransportError as e:
            logger.error(f"ğŸš¨ Elasticsearch ì—°ê²° ë˜ëŠ” ìš”ì²­ ì‹¤íŒ¨: {e.error}, ìƒíƒœ ì½”ë“œ: {e.status_code}")

        except Exception as e:
            logger.error(f"â—ì•Œ ìˆ˜ ì—†ëŠ” ì˜ˆì™¸ ë°œìƒ: {e}")


        ## 2. PDFë¬¸ íŒŒì‹± ë° ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ë³€í™˜  
        #html_contents = preprocessor.pdf_upstageparser(file_name)
        html_contents = preprocessor.pdf_openparse(file_name)
        # html_contents = read_md_file(file_name)
        markdown_texts = preprocessor.html2md_with_spans(html_contents) 

        doc = Document(
            page_content=markdown_texts,
            metadata={"source_pdf": file_name}
        )
        
        ## 3. 1ì°¨ í—¤ë” ê¸°ë°˜ ì²­í¬
        header_chunks = header_splitter.split_documents([doc])

        ## 4. 2ì°¨ ì˜ë¯¸ ê¸°ë°˜ ì²­í¬
        documents = second_splitter.split_documents(header_chunks)

        ## 5. ì¼ê´„ ì„ë² ë”© + ë²¡í„° ì €ì¥
        vectorstore.add_documents(documents)
        logger.info(f"-Ë‹Ëâœ„â”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆ [ì™„ë£Œ] {len(documents)}ê°œ ë¬¸ì„œ Elasticsearchì— ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤. â”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆâ”ˆ\n")

if __name__ == "__main__":
    process_pdfs()